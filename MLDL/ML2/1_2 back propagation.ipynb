{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"1_2 back propagation.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"qV40U7mLZkN4","colab_type":"text"},"source":["# Back Propagation 예제"]},{"cell_type":"markdown","metadata":{"id":"ZVOIj2jKy77Y","colab_type":"text"},"source":["### 예제와 동일한 형태의 neural network 구현하기\n"]},{"cell_type":"markdown","metadata":{"id":"_VCSJ7EnByDL","colab_type":"text"},"source":["- 2-layer Neural Network without bias\n"]},{"cell_type":"code","metadata":{"id":"0KlWlN1wZTfo","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595569450480,"user_tz":-540,"elapsed":3090,"user":{"displayName":"이예준","photoUrl":"","userId":"00427163814690958255"}}},"source":["import tensorflow as tf\n","\n","# input data X와 정답 Y\n","X = tf.Variable([[2], [3]], dtype=tf.float32)\n","Y = tf.Variable([1], dtype=tf.float32)\n","\n","# 첫번째 layer W_1, 두번째 layer W_2\n","W_1 = tf.Variable([[0.11, 0.21], [0.12, 0.08]])\n","W_2 = tf.Variable([[0.14, 0.15]])"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"MVHBvIgZ30EF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":102},"executionInfo":{"status":"ok","timestamp":1595569454804,"user_tz":-540,"elapsed":1261,"user":{"displayName":"이예준","photoUrl":"","userId":"00427163814690958255"}},"outputId":"caed2395-9b3b-4201-e520-706caca6aeaa"},"source":["# forward 연산\n","with tf.GradientTape() as tape:\n","  H_1 = tf.matmul(W_1, X)\n","  Y_hat = tf.matmul(W_2, H_1)\n","  Loss = tf.square(Y_hat - Y) * 1/2\n","  \n","print(\"hidden nodes : \", H_1)\n","print(\"Y_hat : \", Y_hat)\n","print(\"Loss : \", Loss)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["hidden nodes :  tf.Tensor(\n","[[0.84999996]\n"," [0.48      ]], shape=(2, 1), dtype=float32)\n","Y_hat :  tf.Tensor([[0.191]], shape=(1, 1), dtype=float32)\n","Loss :  tf.Tensor([[0.32724053]], shape=(1, 1), dtype=float32)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4mRykrFbCnoW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1595569458524,"user_tz":-540,"elapsed":1459,"user":{"displayName":"이예준","photoUrl":"","userId":"00427163814690958255"}},"outputId":"db903ef7-ec8c-4f8b-e1ba-786b00e34fac"},"source":["# backward 연산 (모델 파라미터에 대해 gradient 계산)\n","(dLoss_dW_1, dLoss_dW_2) = tape.gradient(Loss, [W_1, W_2])\n","print(dLoss_dW_1)\n","print(dLoss_dW_2)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["tf.Tensor(\n","[[-0.22652    -0.33978   ]\n"," [-0.24270001 -0.36405003]], shape=(2, 2), dtype=float32)\n","tf.Tensor([[-0.68764997 -0.38832   ]], shape=(1, 2), dtype=float32)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"g_daZShl_llM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":102},"executionInfo":{"status":"ok","timestamp":1595569464091,"user_tz":-540,"elapsed":989,"user":{"displayName":"이예준","photoUrl":"","userId":"00427163814690958255"}},"outputId":"8ee6af20-d4ed-47e9-c42c-4a652dc81c2a"},"source":["# learning rate 설정\n","lr = 0.05\n","\n","# 모델 파라미터 업데이트\n","W_1 = W_1 - lr * dLoss_dW_1\n","W_2 = W_2 - lr * dLoss_dW_2\n","\n","# 업데이트 된 모델로 다시 forward 연산\n","H_1 = tf.matmul(W_1, X)\n","Y_hat = tf.matmul(W_2, H_1)\n","Loss = tf.square(Y_hat - Y) * 1/2\n","\n","# Y_hat 값이 Y 값에 가까워지고, Loss 값이 작아진 것을 확인할 수 있음  \n","print(\"hidden nodes : \", H_1)\n","print(\"Y_hat : \", Y_hat)\n","print(\"Loss : \", Loss)\n","\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["hidden nodes :  tf.Tensor(\n","[[0.92361903]\n"," [0.55887747]], shape=(2, 1), dtype=float32)\n","Y_hat :  tf.Tensor([[0.2557458]], shape=(1, 1), dtype=float32)\n","Loss :  tf.Tensor([[0.27695718]], shape=(1, 1), dtype=float32)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"i5SEUyQJWd6v","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}