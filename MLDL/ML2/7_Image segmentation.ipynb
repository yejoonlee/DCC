{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"7_Image segmentation.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"cZCM65CBt1CJ"},"source":["##### Copyright 2019 The TensorFlow Authors.\n","\n","Licensed under the Apache License, Version 2.0 (the \"License\");"]},{"cell_type":"code","metadata":{"cellView":"form","colab_type":"code","id":"JOgMcEajtkmg","colab":{}},"source":["#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","# https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"rCSP-dbMw88x"},"source":["# Image segmentation"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"sMP7mglMuGT2"},"source":["수정된 <a href=\"https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/\" class=\"external\">U-Net</a> 을 사용하여 image segmentation task 수행\n","\n","사용할 데이터셋은 Parkhi *et al*. 에 의해 만들어진 [Oxford-IIIT Pet Dataset](https://www.robots.ox.ac.uk/~vgg/data/pets/)\n","\n","- 데이터셋은 이미지와, labe, pixel 단위의 segmentation mask를 포함\n","- 각각의 pixel은 다음 세 category 중 하나에 속함\n","\n","*   Class 1 : pet에 속한 pixel\n","*   Class 2 : pet의 경계에 해당하는 pixel\n","*   Class 3 : 위에 해당하지 않는 pet을 둘러싸고 있는 pixel\n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"MQmKthrSBCld","colab":{}},"source":["!pip install -q git+https://github.com/tensorflow/examples.git\n","!pip install -q -U tfds-nightly"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"YQX7R4bhZy5h","colab":{}},"source":["import tensorflow as tf"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"g87--n2AtyO_","colab":{}},"source":["from tensorflow_examples.models.pix2pix import pix2pix\n","\n","import tensorflow_datasets as tfds\n","tfds.disable_progress_bar()\n","\n","from IPython.display import clear_output\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"oWe0_rQM4JbC"},"source":["## Oxford-IIIT Pets 데이터셋 다운로드"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"40ITeStwDwZb","colab":{}},"source":["dataset, info = tfds.load('oxford_iiit_pet:3.*.*', with_info=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"rJcVdj_U4vzf"},"source":["* 이미지를 flip하기 위한 augmentation 추가\n","* 이미지를 [0,1]의 scale로 normalization\n","* pixel을 0,1,2 중 하나로 labeling"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"FD60EbcAQqov","colab":{}},"source":["def normalize(input_image, input_mask):\n","  input_image = tf.cast(input_image, tf.float32) / 255.0\n","  input_mask -= 1\n","  return input_image, input_mask"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"2NPlCnBXQwb1","colab":{}},"source":["@tf.function\n","def load_image_train(datapoint):\n","  input_image = tf.image.resize(datapoint['image'], (128, 128))\n","  input_mask = tf.image.resize(datapoint['segmentation_mask'], (128, 128))\n","\n","  if tf.random.uniform(()) > 0.5:\n","    input_image = tf.image.flip_left_right(input_image)\n","    input_mask = tf.image.flip_left_right(input_mask)\n","\n","  input_image, input_mask = normalize(input_image, input_mask)\n","\n","  return input_image, input_mask"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Zf0S67hJRp3D","colab":{}},"source":["def load_image_test(datapoint):\n","  input_image = tf.image.resize(datapoint['image'], (128, 128))\n","  input_mask = tf.image.resize(datapoint['segmentation_mask'], (128, 128))\n","\n","  input_image, input_mask = normalize(input_image, input_mask)\n","\n","  return input_image, input_mask"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"65-qHTjX5VZh"},"source":["데이터셋에서 지정한 train / test 분리 기준이 있기 때문에 이를 따라서 분리\n","\n","이 때 dataset을 병렬로 불러올 수 있게 `num_parallel_calls=tf.data.experimental.AUTOTUNE` 사용"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"yHwj2-8SaQli","colab":{}},"source":["TRAIN_LENGTH = info.splits['train'].num_examples\n","BATCH_SIZE = 64\n","BUFFER_SIZE = 1000\n","STEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"39fYScNz9lmo","colab":{}},"source":["train = dataset['train'].map(load_image_train, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n","test = dataset['test'].map(load_image_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"DeFwFDN6EVoI","colab":{}},"source":["train_dataset = train.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n","train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n","test_dataset = test.batch(BATCH_SIZE)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Xa3gMAE_9qNa"},"source":["마스크 시각화 함수 정의"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3N2RPAAW9q4W","colab":{}},"source":["def display(display_list):\n","  plt.figure(figsize=(15, 15))\n","\n","  title = ['Input Image', 'True Mask', 'Predicted Mask']\n","\n","  for i in range(len(display_list)):\n","    plt.subplot(1, len(display_list), i+1)\n","    plt.title(title[i])\n","    plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n","    plt.axis('off')\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"a6u_Rblkteqb","colab":{}},"source":["for image, mask in train.take(1):\n","  sample_image, sample_mask = image, mask\n","display([sample_image, sample_mask])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"FAOe93FRMk3w"},"source":["## 모델 정의\n","U-Net은 encoder(downsampler)와 decoder(upsampler)로 구성되어 있음\n","\n","원활한 학습 및 학습 파라미터의 수를 줄이기 위하여 encoder로는 pre-trained MobileNet V2 의 중간 feature 사용\n","\n","Decoder로는 [Pix2pix tutorial](https://github.com/tensorflow/examples/blob/master/tensorflow_examples/models/pix2pix/pix2pix.py)에서 구현된 upsample block 사용\n","\n","Output이 3개의 channel을 갖는 이유는, 각 픽셀별로 가능한 label이 3개이기 때문"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"c6iB4iMvMkX9","colab":{}},"source":["OUTPUT_CHANNELS = 3"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"W4mQle3lthit"},"source":["[tf.keras.applications](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/applications)에 있는 pre-trained MobileNet V2 사용\n","\n","Encoder는 모델의 특정 layer의 output으로 구성됨\n","- encoder는 학습되지 않음"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"liCeLH0ctjq7","colab":{}},"source":["base_model = tf.keras.applications.MobileNetV2(input_shape=[128, 128, 3], include_top=False)\n","\n","# Use the activations of these layers\n","layer_names = [\n","    'block_1_expand_relu',   # 64x64\n","    'block_3_expand_relu',   # 32x32\n","    'block_6_expand_relu',   # 16x16\n","    'block_13_expand_relu',  # 8x8\n","    'block_16_project',      # 4x4\n","]\n","layers = [base_model.get_layer(name).output for name in layer_names]\n","\n","# Create the feature extraction model\n","down_stack = tf.keras.Model(inputs=base_model.input, outputs=layers)\n","\n","down_stack.trainable = False"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"KPw8Lzra5_T9"},"source":["Decoder는 TensorFlow의 example module을 사용하여 구현"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"p0ZbfywEbZpJ","colab":{}},"source":["up_stack = [\n","    pix2pix.upsample(512, 3),  # 4x4 -> 8x8\n","    pix2pix.upsample(256, 3),  # 8x8 -> 16x16\n","    pix2pix.upsample(128, 3),  # 16x16 -> 32x32\n","    pix2pix.upsample(64, 3),   # 32x32 -> 64x64\n","]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"45HByxpVtrPF","colab":{}},"source":["def unet_model(output_channels):\n","  inputs = tf.keras.layers.Input(shape=[128, 128, 3])\n","  x = inputs\n","\n","  # Downsampling through the model\n","  skips = down_stack(x)\n","  x = skips[-1]\n","  skips = reversed(skips[:-1])\n","\n","  # Upsampling and establishing the skip connections\n","  for up, skip in zip(up_stack, skips):\n","    x = up(x)\n","    concat = tf.keras.layers.Concatenate()\n","    x = concat([x, skip])\n","\n","  # This is the last layer of the model\n","  last = tf.keras.layers.Conv2DTranspose(\n","      output_channels, 3, strides=2,\n","      padding='same')  #64x64 -> 128x128\n","\n","  x = last(x)\n","\n","  return tf.keras.Model(inputs=inputs, outputs=x)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"j0DGH_4T0VYn"},"source":["## 모델 학습\n","`losses.SparseCategoricalCrossentropy(from_logits=True)`를 사용하여 모델 loss 계산 (multi-class prediction 문제와 같기 때문에)"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"6he36HK5uKAc","colab":{}},"source":["model = unet_model(OUTPUT_CHANNELS)\n","model.compile(optimizer='adam',\n","              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","              metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"xVMzbIZLcyEF"},"source":["모델 구조 시각화"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"sw82qF1Gcovr","colab":{}},"source":["tf.keras.utils.plot_model(model, show_shapes=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Tc3MiEO2twLS"},"source":["학습 전에는 어떻게 예측하는지 test"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"UwvIKLZPtxV_","colab":{}},"source":["def create_mask(pred_mask):\n","  pred_mask = tf.argmax(pred_mask, axis=-1)\n","  pred_mask = pred_mask[..., tf.newaxis]\n","  return pred_mask[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"YLNsrynNtx4d","colab":{}},"source":["def show_predictions(dataset=None, num=1):\n","  if dataset:\n","    for image, mask in dataset.take(num):\n","      pred_mask = model.predict(image)\n","      display([image[0], mask[0], create_mask(pred_mask)])\n","  else:\n","    display([sample_image, sample_mask,\n","             create_mask(model.predict(sample_image[tf.newaxis, ...]))])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"X_1CC0T4dho3","colab":{}},"source":["show_predictions()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"22AyVYWQdkgk"},"source":["아래에 정의된 callback 함수를 사용하여 모델이 어떻게 학습되는지 확인"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"wHrHsqijdmL6","colab":{}},"source":["class DisplayCallback(tf.keras.callbacks.Callback):\n","  def on_epoch_end(self, epoch, logs=None):\n","    clear_output(wait=True)\n","    show_predictions()\n","    print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"StKDH_B9t4SD","colab":{}},"source":["EPOCHS = 5\n","VAL_SUBSPLITS = 5\n","VALIDATION_STEPS = info.splits['test'].num_examples//BATCH_SIZE//VAL_SUBSPLITS\n","\n","model_history = model.fit(train_dataset, epochs=EPOCHS,\n","                          steps_per_epoch=STEPS_PER_EPOCH,\n","                          validation_steps=VALIDATION_STEPS,\n","                          validation_data=test_dataset,\n","                          callbacks=[DisplayCallback()])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"P_mu0SAbt40Q","colab":{}},"source":["loss = model_history.history['loss']\n","val_loss = model_history.history['val_loss']\n","\n","epochs = range(EPOCHS)\n","\n","plt.figure()\n","plt.plot(epochs, loss, 'r', label='Training loss')\n","plt.plot(epochs, val_loss, 'bo', label='Validation loss')\n","plt.title('Training and Validation Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss Value')\n","plt.ylim([0, 1])\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"unP3cnxo_N72"},"source":["## 예측해보기"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ikrzoG24qwf5","colab":{}},"source":["show_predictions(test_dataset, 3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sHG7lkQm2TT2","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}