{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"9_Feature extraction using a pre-trained model and fine tuning.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"77gENRVX40S7"},"source":["##### Copyright 2019 The TensorFlow Authors."]},{"cell_type":"code","metadata":{"cellView":"form","colab_type":"code","id":"d8jyt37T42Vf","colab":{}},"source":["#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","# https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","colab_type":"code","id":"aPxHdjwW5P2j","colab":{}},"source":["#@title MIT License\n","#\n","# Copyright (c) 2017 François Chollet                                                                                                                    # IGNORE_COPYRIGHT: cleared by OSS licensing\n","#\n","# Permission is hereby granted, free of charge, to any person obtaining a\n","# copy of this software and associated documentation files (the \"Software\"),\n","# to deal in the Software without restriction, including without limitation\n","# the rights to use, copy, modify, merge, publish, distribute, sublicense,\n","# and/or sell copies of the Software, and to permit persons to whom the\n","# Software is furnished to do so, subject to the following conditions:\n","#\n","# The above copyright notice and this permission notice shall be included in\n","# all copies or substantial portions of the Software.\n","#\n","# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n","# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n","# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n","# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n","# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n","# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n","# DEALINGS IN THE SOFTWARE."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"hRTa3Ee15WsJ"},"source":["# 미리 학습된 CNN 모델로 Transfer learning"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"2X4KyhORdSeO"},"source":["In this tutorial, you will learn how to classify images of cats and dogs by using transfer learning from a pre-trained network.\n","\n","이미 큰 데이터셋으로 학습된 CNN 모델의 feature를 사용하여 고양이와 강아지를 분류하는 모델을 fine-tuning\n","- 이미 잘 학습된 filter 값들을 사용하여 feature map들을 만들어내기 때문에, 빠르게 학습할 수 있다는 장점이 있음\n","- frozen 모델의 상위 layer 몇 개만 새롭게 추가된 분류 layer와 함께 학습을 시키고, 나머지 layer들은 고정된 채로 학습에 참여\n","\n","다음과 같은 순서로 진행\n","1. 데이터셋 파악\n","1. Keras ImageDataGenerator를 이용한 pipeline 제작\n","1. 모델 구성\n","   * pretrained base model 및 weights 불러오기\n","   * 분류를 위한 layer 추가\n","1. 모델 학습\n","1. 모델 평가\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"iBMcobPHdD8O","colab":{}},"source":["import os\n","\n","import numpy as np\n","\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"TqOt6Sv7AsMi","colab":{}},"source":["import tensorflow as tf\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"v77rlkCKW0IJ"},"source":["## 전처리"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"0GoKGm1duzgk"},"source":["### 데이터 다운로드"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"vHP9qMJxt2oz"},"source":["[TensorFlow Datasets](http://tensorflow.org/datasets) 으로 부터 고양이와 강아지 데이터셋 로드\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"KVh7rDVAuW8Y","colab":{}},"source":["import tensorflow_datasets as tfds\n","tfds.disable_progress_bar()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Nsoic6bGuwQ-"},"source":["`\"cats_vs_dogs\"` 데이터셋은 정해진 training / validation 분리 비율이 없기 때문에, 임의로 (train, validation, test)를 (80%, 10%, 10%)로 분리"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ro4oYaEmxe4r","colab":{}},"source":["(raw_train, raw_validation, raw_test), metadata = tfds.load(\n","    'cats_vs_dogs',\n","    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n","    with_info=True,\n","    as_supervised=True,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"o29EfE-p0g5X"},"source":["RGB 3 채널과 데이터 type이 int임을 확인 할 수 있음"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"GIys1_zY1S9b","colab":{}},"source":["print(raw_train)\n","print(raw_validation)\n","print(raw_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"yO1Q2JaW5sIy"},"source":["학습 데이터셋의 첫 두 이미지와 정답을 출력"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"K5BeQyKThC_Y","colab":{}},"source":["get_label_name = metadata.features['label'].int2str\n","\n","for image, label in raw_train.take(2):\n","  plt.figure()\n","  plt.imshow(image)\n","  plt.title(get_label_name(label))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"wvidPx6jeFzf"},"source":["### 데이터 formatting"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"y3PM6GVHcC31","colab":{}},"source":["IMG_SIZE = 160 # All images will be resized to 160x160\n","\n","def format_example(image, label):\n","  image = tf.cast(image, tf.float32)\n","  image = (image/127.5) - 1\n","  image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n","  return image, label"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"i2MRh_AeBtOM"},"source":["map 함수를 사용하여 위의 전처리 함수를 적용"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"SFZ6ZW7KSXP9","colab":{}},"source":["train = raw_train.map(format_example)\n","validation = raw_validation.map(format_example)\n","test = raw_test.map(format_example)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"E5ifgXDuBfOC"},"source":["batch 구성 & shuffle"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Yic-I66m6Isv","colab":{}},"source":["BATCH_SIZE = 32\n","SHUFFLE_BUFFER_SIZE = 1000"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"p3UUPdm86LNC","colab":{}},"source":["train_batches = train.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n","validation_batches = validation.batch(BATCH_SIZE)\n","test_batches = test.batch(BATCH_SIZE)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"iknFo3ELBVho","colab":{}},"source":["for image_batch, label_batch in train_batches.take(1):\n","   pass\n","\n","image_batch.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"OkH-kazQecHB"},"source":["## pre-trained CNN으로부터 base 모델 생성\n","You will create the base model from the **MobileNet V2** model developed at Google. This is pre-trained on the ImageNet dataset, a large dataset consisting of 1.4M images and 1000 classes. ImageNet is a research training dataset with a wide variety of categories like `jackfruit` and `syringe`. This base of knowledge will help us classify cats and dogs from our specific dataset.\n","\n","Google의 **MobileNet V2**으로부터 base 모델 생성\n","ImageNet dataset으로 미리 학습된 모델 (1.4M 이미지 & 1000 classes)\n","ImageNet으로 학습된 parameter들이 고양이&강아지를 분류하는데 도움을 줌\n","\n","feature extraction을 위해 사용할 MobileNet V2의 layer를 선정\n","- 마지막 layer는 ImageNet의 분류를 위한 layer이기 때문에 도움이 안 됨\n","- Flatten operation 이전의 layer를 일반적으로 사용 (bottleneck layer 라고 함)\n","- **include_top=False** argument을 설정함으로써, 마지막 분류를 위한 layer를 제외한 모델을 불러올 수 있음\n","\n","First, you need to pick which layer of MobileNet V2 you will use for feature extraction. The very last classification layer (on \"top\", as most diagrams of machine learning models go from bottom to top) is not very useful.  Instead, you will follow the common practice to depend on the very last layer before the flatten operation. This layer is called the \"bottleneck layer\". The bottleneck layer features retain more generality as compared to the final/top layer.\n","\n","First, instantiate a MobileNet V2 model pre-loaded with weights trained on ImageNet. By specifying the **include_top=False** argument, you load a network that doesn't include the classification layers at the top, which is ideal for feature extraction."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"19IQ2gqneqmS","colab":{}},"source":["IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n","\n","# Create the base model from the pre-trained model MobileNet V2\n","base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n","                                               include_top=False,\n","                                               weights='imagenet')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"AqcsxoJIEVXZ"},"source":["Feature extractor는 `160x160x3` 이미지를 `5x5x1280` 의 feature로 변환"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Y-2LJL0EEUcx","colab":{}},"source":["feature_batch = base_model(image_batch)\n","print(feature_batch.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"rlx56nQtfe8Y"},"source":["## Feature extraction"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"CnMLieHBCwil"},"source":["### Freeze the convolutional base\n","\n","모델을 학습시키기 전에 base CNN 모델을 freeze 시켜놓는 것이 필요\n","- base CNN 모델의 학습 parameter가 update 되지 않도록"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"OTCJH4bphOeo","colab":{}},"source":["base_model.trainable = False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"KpbzSmPkDa-N","colab":{}},"source":["# Let's take a look at the base model architecture\n","base_model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"wdMRM8YModbk"},"source":["### Classification head 추가"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"QBc31c4tMOdH"},"source":["이미지당 1280-element vector를 만들어 낼 수 있도록 `tf.keras.layers.GlobalAveragePooling2D` layer를 사용하여 `5x5` 마다 평균내는 pooling 사용"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"dLnpMF5KOALm","colab":{}},"source":["global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n","feature_batch_average = global_average_layer(feature_batch)\n","print(feature_batch_average.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"O1p0OJBR6dOT"},"source":["분류를 위한 `tf.keras.layers.Dense` layer를 추가"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Wv4afXKj6cVa","colab":{}},"source":["prediction_layer = tf.keras.layers.Dense(1)\n","prediction_batch = prediction_layer(feature_batch_average)\n","print(prediction_batch.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"0iqnBeZrfoIc"},"source":["`tf.keras.Sequential` 을 사용하여 base CNN 모델 (feature extractor) 위에 2개의 layer를 추가"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"eApvroIyn1K0","colab":{}},"source":["model = tf.keras.Sequential([\n","  base_model,\n","  global_average_layer,\n","  prediction_layer\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"g0ylJXE_kRLi"},"source":["### 모델 컴파일\n","\n","모델이 logit 값을 output으로 갖기 때문에 `from_logits=True` argument 세팅"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"RpR8HdyMhukJ","colab":{}},"source":["base_learning_rate = 0.0001\n","model.compile(optimizer=tf.optimizers.RMSprop(lr=base_learning_rate),\n","              loss=tf.losses.BinaryCrossentropy(from_logits=True),\n","              metrics=[tf.metrics.BinaryAccuracy(threshold=0.0, name='accuracy')])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"I8ARiyMFsgbH","colab":{}},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"lxOcmVr0ydFZ"},"source":["약 200만개의 parameter가 학습 되지 않고, 학습되는 parameter는 오직 마지막 분류를 위한 Dense layer에만 존재"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"krvBumovycVA","colab":{}},"source":["len(model.trainable_variables)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"RxvgOYTDSWTx"},"source":["### 모델 학습\n","\n","10 epoch 학습 후 ~96% 정확도를 보임\n","\n","1 epoch만 학습하여 test\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Om4O3EESkab1","colab":{}},"source":["initial_epochs = 2\n","validation_steps=20\n","\n","loss0,accuracy0 = model.evaluate(validation_batches, steps = validation_steps)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"8cYT1c48CuSd","colab":{}},"source":["print(\"initial loss: {:.2f}\".format(loss0))\n","print(\"initial accuracy: {:.2f}\".format(accuracy0))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"JsaRFlZ9B6WK","colab":{}},"source":["history = model.fit(train_batches,\n","                    epochs=initial_epochs,\n","                    validation_data=validation_batches)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Hd94CKImf8vi"},"source":["### 학습 curve 확인"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"53OTCh3jnbwV","colab":{}},"source":["acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","plt.figure(figsize=(8, 8))\n","plt.subplot(2, 1, 1)\n","plt.plot(acc, label='Training Accuracy')\n","plt.plot(val_acc, label='Validation Accuracy')\n","plt.legend(loc='lower right')\n","plt.ylabel('Accuracy')\n","plt.ylim([min(plt.ylim()),1])\n","plt.title('Training and Validation Accuracy')\n","\n","plt.subplot(2, 1, 2)\n","plt.plot(loss, label='Training Loss')\n","plt.plot(val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.ylabel('Cross Entropy')\n","plt.ylim([0,1.0])\n","plt.title('Training and Validation Loss')\n","plt.xlabel('epoch')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"foWMyyUHbc1j"},"source":["학습에 `tf.keras.layers.BatchNormalization`, `tf.keras.layers.Dropout`이 사용되기 때문에 validation metric이 training metric 보다 더 좋은 성능을 기록할 수 있음\n","\n","또한, validation은 학습이 진행된 후 측정되는 것이기 때문에, training 때보다 좋은 성능을 기록할 수 있음"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"CqwV-CRdS6Nv"},"source":["## Fine tuning\n","\n","모델의 성능을 향상시키는 다른 방법: pre-trained base CNN 모델의 최상위 layer를 학습에 참여시킴\n","\n","학습이 진행되면서 이미 학습되었던 weight 들이 우리의 task에 맞게 loss가 작게 생성되도록 변화해 나감\n","\n","단, 분류를 위한 layer를 먼저 학습시키고 난 후, 학습 가능하도록 전환해야함\n","(random하게 초기화되어 있는 분류 layer와 처음부터 같이 학습해버리면, gradient의 값이 엄청 크게 나오기 때문에 ImageNet으로 학습했던 것들을 잊어버림)\n","\n","또한, fine-tune에 사용되는 상위 layer는 전체 MobileNet base 모델 대비 소수여야 함\n","- 일반적으로 CNN 모델의 상위 layer는 task를 위해 특화가 되어지고, 하위 layer는 일반적인 이미지의 특징을 잡기 위한 방향으로 학습이 되어지기 때문에 이 부분은 살려야 함\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"CPXnzUK0QonF"},"source":["### base CNN 모델의 상위 레이어 parameter un-freeze\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"rfxv_ifotQak"},"source":["Base CNN 모델의 상위 레이어들을 학습 가능한 상태로 바꾸고, 하위 레이어들은 학습이 불가능 하도록 세팅하여 recompile"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"4nzcagVitLQm","colab":{}},"source":["base_model.trainable = True"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"-4HgVAacRs5v","colab":{}},"source":["# Let's take a look to see how many layers are in the base model\n","print(\"Number of layers in the base model: \", len(base_model.layers))\n","\n","# Fine-tune from this layer onwards\n","fine_tune_at = 100\n","\n","# Freeze all the layers before the `fine_tune_at` layer\n","for layer in base_model.layers[:fine_tune_at]:\n","  layer.trainable =  False"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"4Uk1dgsxT0IS"},"source":["### 모델 컴파일\n","\n","작은 learning rate 사용 (이미 학습이 많이 진행된 모델이기 때문에)"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"NtUnaz0WUDva","colab":{}},"source":["model.compile(loss=tf.losses.BinaryCrossentropy(from_logits=True),\n","              optimizer = tf.optimizers.RMSprop(lr=base_learning_rate/10),\n","              metrics=[tf.metrics.BinaryAccuracy(threshold=0.0, name='accuracy')])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"WwBWy7J2kZvA","colab":{}},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"bNXelbMQtonr","colab":{}},"source":["len(model.trainable_variables)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"4G5O4jd6TuAG"},"source":["### 모델 학습"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ECQLkAsFTlun","colab":{}},"source":["fine_tune_epochs = 2\n","total_epochs =  initial_epochs + fine_tune_epochs\n","\n","history_fine = model.fit(train_batches,\n","                         epochs=total_epochs,\n","                         initial_epoch =  history.epoch[-1],\n","                         validation_data=validation_batches)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"TfXEmsxQf6eP"},"source":["학습을 많이 진행한 후 학습 curve를 살펴보면, validation loss가 training loss보다 훨씬 큰 overfitting 현상을 발견할 수 있음\n","(이미 비슷한 성격의 ImageNet 데이터셋으로 충분히 학습을 시킨 상태이고, 새로운 데이터셋이 ImageNet에 비하면 상대적으로 작기 때문)\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"PpA8PlpQKygw","colab":{}},"source":["acc += history_fine.history['accuracy']\n","val_acc += history_fine.history['val_accuracy']\n","\n","loss += history_fine.history['loss']\n","val_loss += history_fine.history['val_loss']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"chW103JUItdk","colab":{}},"source":["plt.figure(figsize=(8, 8))\n","plt.subplot(2, 1, 1)\n","plt.plot(acc, label='Training Accuracy')\n","plt.plot(val_acc, label='Validation Accuracy')\n","plt.ylim([0.8, 1])\n","plt.plot([initial_epochs-1,initial_epochs-1],\n","          plt.ylim(), label='Start Fine Tuning')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation Accuracy')\n","\n","plt.subplot(2, 1, 2)\n","plt.plot(loss, label='Training Loss')\n","plt.plot(val_loss, label='Validation Loss')\n","plt.ylim([0, 1.0])\n","plt.plot([initial_epochs-1,initial_epochs-1],\n","         plt.ylim(), label='Start Fine Tuning')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss')\n","plt.xlabel('epoch')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"_TZTwG7nhm0C"},"source":["## 요약:\n","\n","* **Feature extraction을 위한 미리 학습된 모델 사용**:  \n","작은 데이터셋으로 학습을 진행할 때, 큰 데이터셋으로 미리 학습해놓은 모델의 feature를 사용하는 것이 일반적\n","  - pre-trained 모델을 불러와서 분류를 위한 layer를 제외한 나머지 layer의 parameter를 학습 불가능 상태(freeze)로 바꿔놓고, 분류를 위한 layer만 학습 진행\n","\n","* **Fine-tuning**: \n","모델의 성능을 더욱 향상시키기 위해서 pre-trained base 모델의 상위 layer 들 일부를 학습 가능상태로 전환\n","  - 새로 학습시키는 데이터셋이 크고, base 모델을 학습시킨 데이터셋과 비슷할 경우 권장됨\n"]}]}