{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"11_RNN models.ipynb","provenance":[{"file_id":"1oFNGv8rpK4rTQerlk75AFtRMNdpzKMiE","timestamp":1595421640718},{"file_id":"14QMN8BstnVcnXcDPYbbvMleBCRPfRijT","timestamp":1595415273791}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"qV40U7mLZkN4"},"source":["# Tensorflow 실습 : Recurrent Neural Networks (RNNs)"]},{"cell_type":"markdown","metadata":{"id":"h5X9HqjFaFVK"},"source":["## RNN layers"]},{"cell_type":"code","metadata":{"id":"KAgXBP8LtArB"},"source":["import tensorflow as tf"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6madZY2m1zsO"},"source":["- Tensorflow에서 제공하는 일반적인 RNN layers\n","  - 기본 RNN: tf.keras.layers.SimpleRNN\n","  - LSTM: tf.keras.layers.LSTM\n","  - GRU: tf.keras.layers.GRU"]},{"cell_type":"code","metadata":{"id":"lR32V84D2MQi","executionInfo":{"status":"ok","timestamp":1596005905278,"user_tz":-540,"elapsed":9498,"user":{"displayName":"이예준","photoUrl":"","userId":"00427163814690958255"}},"outputId":"f30ac720-e9e9-4997-dc86-c87e430dbb49","colab":{"base_uri":"https://localhost:8080/","height":221}},"source":["# 기본적으로 RNN layer의 입력 tensor shape는 [batch, timesteps, feature]로 3D tensor\n","# 여기서 input은 16개의 time step을 가지고, 각 time step 마다 32차원의 값을 가지는 형태\n","sequence_len = 16\n","feature_dim = 32\n","input_sequence = tf.keras.Input(shape=(sequence_len, feature_dim))\n","\n","# units은 RNN layer의 hidden size를 의미함\n","units = 64\n","rnn = tf.keras.Sequential([  \n","  tf.keras.layers.SimpleRNN(units),\n","  tf.keras.layers.Dense(4, activation='softmax')\n","])\n","\n","# input sequence를 입력해서 모델을 build\n","rnn(input_sequence)\n","# RNN layer의 출력 shape를 보면, 시간 축이 사라진 것을 확인\n","# 마지막 time step의 output을 return\n","rnn.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","simple_rnn (SimpleRNN)       (None, 64)                6208      \n","_________________________________________________________________\n","dense (Dense)                (None, 4)                 260       \n","=================================================================\n","Total params: 6,468\n","Trainable params: 6,468\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_g3De1ls6LoS","executionInfo":{"status":"ok","timestamp":1596005912452,"user_tz":-540,"elapsed":1019,"user":{"displayName":"이예준","photoUrl":"","userId":"00427163814690958255"}},"outputId":"bfe96775-dc90-4a4c-9270-43962f114425","colab":{"base_uri":"https://localhost:8080/","height":221}},"source":["# RNN layer를 정의할 때, return_sequences=True로 설정해주면 시간축이 유지되도록 return\n","rnn = tf.keras.Sequential([  \n","  tf.keras.layers.SimpleRNN(units, return_sequences=True),\n","  tf.keras.layers.Dense(4, activation='softmax')\n","])\n","\n","rnn(input_sequence)\n","# 시간 축에 따라, 모든 time step에 대한 output을 출력\n","# 마지막 dense layer도 모든 time step에 대해 동일하게 적용됨\n","rnn.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","simple_rnn_1 (SimpleRNN)     (None, 16, 64)            6208      \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 16, 4)             260       \n","=================================================================\n","Total params: 6,468\n","Trainable params: 6,468\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FTRg8zBQF4Yx","executionInfo":{"status":"ok","timestamp":1596006229411,"user_tz":-540,"elapsed":1031,"user":{"displayName":"이예준","photoUrl":"","userId":"00427163814690958255"}},"outputId":"8fef8087-2edd-4a16-a23c-f0224614e804","colab":{"base_uri":"https://localhost:8080/","height":289}},"source":["# RNN layer를 여러 층 쌓을 때 return_sequences=True가 꼭 필요함\n","rnn = tf.keras.Sequential([  \n","  tf.keras.layers.SimpleRNN(units, return_sequences=True),\n","  tf.keras.layers.SimpleRNN(units, return_sequences=True),\n","  tf.keras.layers.SimpleRNN(units),\n","  tf.keras.layers.Dense(4, activation='softmax')\n","])\n","\n","rnn(input_sequence)\n","rnn.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","simple_rnn_2 (SimpleRNN)     (None, 16, 64)            6208      \n","_________________________________________________________________\n","simple_rnn_3 (SimpleRNN)     (None, 16, 64)            8256      \n","_________________________________________________________________\n","simple_rnn_4 (SimpleRNN)     (None, 64)                8256      \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 4)                 260       \n","=================================================================\n","Total params: 22,980\n","Trainable params: 22,980\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aYKOhpnx7MCA","executionInfo":{"status":"ok","timestamp":1596006256839,"user_tz":-540,"elapsed":1097,"user":{"displayName":"이예준","photoUrl":"","userId":"00427163814690958255"}},"outputId":"5fbc725b-727e-4523-b44c-204e8b9501c2","colab":{"base_uri":"https://localhost:8080/","height":221}},"source":["# LSTM을 사용하는 방법도 동일함 \n","lstm = tf.keras.Sequential([  \n","  tf.keras.layers.LSTM(units),\n","  tf.keras.layers.Dense(4, activation='softmax')\n","])\n","\n","lstm(input_sequence)\n","# 기본 RNN layer보다 훨씬 많은 파라미터 수를 가지고 있음\n","lstm.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","lstm (LSTM)                  (None, 64)                24832     \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 4)                 260       \n","=================================================================\n","Total params: 25,092\n","Trainable params: 25,092\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EC80tzdo7kEK","executionInfo":{"status":"ok","timestamp":1596006317920,"user_tz":-540,"elapsed":985,"user":{"displayName":"이예준","photoUrl":"","userId":"00427163814690958255"}},"outputId":"a3966521-90d4-44bd-8e15-dfeed91f648c","colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["# return_state=True 로 설정하면, LSTM의 마지막 cell state와 hidden state를 모두 return 받을 수 있음\n","# tf.keras.Sequenctial에서는 각 layer의 output이 1개일때만 사용할수 있으므로, 적합하지 않음\n","class LSTM(tf.keras.Model):\n","    def __init__(self):\n","        super(LSTM, self).__init__()\n","        self.lstm_layer = tf.keras.layers.LSTM(units, return_sequences=True, return_state=True)\n","        self.dense = tf.keras.layers.Dense(4, activation='softmax')\n","\n","    def call(self, inputs):        \n","        whole_seq_output, final_hidden_state, final_cell_state = self.lstm_layer(inputs)\n","        \n","        # shape를 출력\n","        print(\"whole_seq_output :\", whole_seq_output.shape)\n","        print(\"final_hidden_state :\", final_hidden_state.shape)\n","        print(\"final_cell_state :\", final_cell_state.shape)\n","\n","        output_prob = self.dense(whole_seq_output)\n","        return output_prob\n","\n","lstm = LSTM()\n","lstm(input_sequence)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["whole_seq_output : (None, 16, 64)\n","final_hidden_state : (None, 64)\n","final_cell_state : (None, 64)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor 'lstm_1/Identity:0' shape=(None, 16, 4) dtype=float32>"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"GKYC7UzpBDaN","executionInfo":{"status":"ok","timestamp":1596006619737,"user_tz":-540,"elapsed":1022,"user":{"displayName":"이예준","photoUrl":"","userId":"00427163814690958255"}},"outputId":"b053da7f-1892-4a0d-f602-a81a28ad90f5","colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["# GRU는 state가 하나로 되어있음\n","class GRU(tf.keras.Model):\n","    def __init__(self):\n","        super(GRU, self).__init__()\n","        self.gru_layer = tf.keras.layers.GRU(units, return_sequences=True, return_state=True)\n","        self.dense = tf.keras.layers.Dense(4, activation='softmax')\n","\n","    def call(self, inputs):        \n","        whole_seq_output, final_state = self.gru_layer(inputs)\n","\n","        # shape를 출력\n","        print(\"whole_seq_output :\", whole_seq_output.shape)\n","        print(\"final_state :\", final_state.shape)\n","        \n","        output_prob = self.dense(whole_seq_output)\n","        return output_prob\n","\n","gru = GRU()\n","gru(input_sequence)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["whole_seq_output : (None, 16, 64)\n","final_state : (None, 64)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor 'gru/Identity:0' shape=(None, 16, 4) dtype=float32>"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"Jx6UkuneSmBU"},"source":["## Bidirectional RNNs"]},{"cell_type":"markdown","metadata":{"id":"oVL7Zu0nCXRk"},"source":["- Bidirectional RNN layer를 만들기 위해서, Wrapper 형태로 활용가능한 layer를 제공함\n","  - tf.keras.layers.Bidirectional\n","- Bidirectional로 활용하고자 하는 RNN layer를 감싸주는 형태로 구현"]},{"cell_type":"code","metadata":{"id":"syhqwD6ZCW0a","executionInfo":{"status":"ok","timestamp":1596006766074,"user_tz":-540,"elapsed":1487,"user":{"displayName":"이예준","photoUrl":"","userId":"00427163814690958255"}},"outputId":"e16c405b-e0df-4ee3-9b14-9279b480fea5","colab":{"base_uri":"https://localhost:8080/","height":221}},"source":["model = tf.keras.Sequential()\n","model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units)))\n","model.add(tf.keras.layers.Dense(4, activation='softmax'))\n","\n","model(input_sequence)\n","# 양방향의 hidden state를 모두 출력하므로, output 차원이 2배 (64 * 2)\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_4\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","bidirectional (Bidirectional (None, 128)               49664     \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 4)                 516       \n","=================================================================\n","Total params: 50,180\n","Trainable params: 50,180\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AIctpo6LIKiU","executionInfo":{"status":"ok","timestamp":1596006891436,"user_tz":-540,"elapsed":1365,"user":{"displayName":"이예준","photoUrl":"","userId":"00427163814690958255"}},"outputId":"977b2297-dc86-43cd-f433-76d6b36e2612","colab":{"base_uri":"https://localhost:8080/","height":255}},"source":["# bidirectional RNN layer를 여러 층 쌓는 것도 가능\n","model = tf.keras.Sequential()\n","model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units, return_sequences=True)))\n","model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units)))\n","model.add(tf.keras.layers.Dense(4, activation='softmax'))\n","\n","model(input_sequence)\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_5\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","bidirectional_1 (Bidirection (None, 16, 128)           49664     \n","_________________________________________________________________\n","bidirectional_2 (Bidirection (None, 128)               98816     \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 4)                 516       \n","=================================================================\n","Total params: 148,996\n","Trainable params: 148,996\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"SGNOzySqI-os"},"source":["## TimeDistributed 이해 및 활용\n"]},{"cell_type":"markdown","metadata":{"id":"yu_95Z8fJO8i"},"source":["- 시간 축에 대해 동일한 파라미터의 layer를 적용하는 방법\n","- RNN layer와 직접적으로 관련된 것은 아니지만, sequence 데이터를 다루다보면 꼭 필요한 기능\n","- 동일하게 적용할 layer를 wrapper로 감싸서 사용\n","  - tf.keras.layers.TimeDistributed\n","- Dense layer는 마지막 축(axis)에 대해 계산하므로, TimeDistributed가 자동으로 적용됨"]},{"cell_type":"code","metadata":{"id":"Y2lBvyfKJ6gN","executionInfo":{"status":"ok","timestamp":1596006930612,"user_tz":-540,"elapsed":974,"user":{"displayName":"이예준","photoUrl":"","userId":"00427163814690958255"}},"outputId":"0bc18050-e3bc-48ce-f02a-44e71fd168ec","colab":{"base_uri":"https://localhost:8080/","height":221}},"source":["# RNN layer의 output을 dense layer에 통과 시키는 것은 시간 축에 따라 동일한 파라미터를 활용하는 것임\n","rnn = tf.keras.Sequential([  \n","  tf.keras.layers.SimpleRNN(units, return_sequences=True),\n","  tf.keras.layers.Dense(4, activation='softmax')\n","])\n","\n","rnn(input_sequence)\n","rnn.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_6\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","simple_rnn_5 (SimpleRNN)     (None, 16, 64)            6208      \n","_________________________________________________________________\n","dense_8 (Dense)              (None, 16, 4)             260       \n","=================================================================\n","Total params: 6,468\n","Trainable params: 6,468\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qBlveRc4KGQk","executionInfo":{"status":"ok","timestamp":1596006951405,"user_tz":-540,"elapsed":1007,"user":{"displayName":"이예준","photoUrl":"","userId":"00427163814690958255"}},"outputId":"b08d4ea3-238a-4f1c-d74e-269716101e0b","colab":{"base_uri":"https://localhost:8080/","height":221}},"source":["# TimeDistributed를 활용하는 예시\n","# 위의 셀에서도 자동적으로 시간 축에 대해 동일한 파라미터를 사용하므로, 결과는 완전히 동일함\n","rnn = tf.keras.Sequential([  \n","  tf.keras.layers.SimpleRNN(units, return_sequences=True),\n","  tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(4, activation='softmax'))\n","])\n","\n","rnn(input_sequence)\n","rnn.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_7\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","simple_rnn_6 (SimpleRNN)     (None, 16, 64)            6208      \n","_________________________________________________________________\n","time_distributed (TimeDistri (None, 16, 4)             260       \n","=================================================================\n","Total params: 6,468\n","Trainable params: 6,468\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4gVCRhvwKuCx"},"source":["- 아래는 TimeDistributed가 꼭 필요한 상황의 예시\n","- 비디오 데이터 예시\n","  - sequence length는 10\n","  - 각 frame의 이미지는 128 x 128\n","  - 각 이미지의 채널 수는 3\n","- time step에 따라, 서로 다른 이미지에 동일한 CNN layer를 적용해야 하는 상황"]},{"cell_type":"code","metadata":{"id":"QG79loPTKsbV","executionInfo":{"status":"ok","timestamp":1596006970553,"user_tz":-540,"elapsed":916,"user":{"displayName":"이예준","photoUrl":"","userId":"00427163814690958255"}},"outputId":"21478200-bdb1-418e-a688-06d94b9f33d3","colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["# input shape : [sequence length, width, height, channel]\n","inputs = tf.keras.Input(shape=(10, 128, 128, 3))\n","\n","model = tf.keras.Sequential([\n","  tf.keras.layers.TimeDistributed(tf.keras.layers.Conv2D(64, (3, 3)))\n","])\n","\n","model(inputs)\n","# 모든 time step에 대해 동일한 cnn layer 적용된 것 확인\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_8\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","time_distributed_1 (TimeDist (None, 10, 126, 126, 64)  1792      \n","=================================================================\n","Total params: 1,792\n","Trainable params: 1,792\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bzsxMhV_bbCU"},"source":[""],"execution_count":null,"outputs":[]}]}