{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"6_Ensemble.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"eiory5W_FV1x","colab_type":"text"},"source":["# 앙상블 실습"]},{"cell_type":"markdown","metadata":{"id":"GWvL6HnCFXf3","colab_type":"text"},"source":["수업 시간에 test data에 대한 예측 정확도를 높이는 방법으로 앙상블이 사용된다고 설명한 바 있다. 앙상블을 한 마디로 표현하면 **집단 지성**으로, 여러 가지 모델을 결합해 최종 예측을 진행한다. 주로 variance를 줄이는 데 큰 역할을 하는 앙상블은 대부분의 task에서 성능이 매우 뛰어난 방법론이라 알려져 있다. "]},{"cell_type":"markdown","metadata":{"id":"xRbgGfAmGOtm","colab_type":"text"},"source":["### 합의 기반 결합"]},{"cell_type":"markdown","metadata":{"id":"5pV206rPGSBX","colab_type":"text"},"source":["앙상블 방법론은 머신 러닝 모델의 결합 방법에 따라 합의 기반 결합과 학습 기반 결합으로 나눌 수 있다. 이번 실습에서는 합의 기반 결합에 대해 알아보자."]},{"cell_type":"markdown","metadata":{"id":"YFRfA_dWQ6_E","colab_type":"text"},"source":["![](https://miro.medium.com/max/700/1*I7NsQXwyR36XK62s1iDNzQ.png)"]},{"cell_type":"markdown","metadata":{"id":"K_7VFBYbO4QW","colab_type":"text"},"source":["합의 기반 결합은 쉽게 말해 **다수결**을 이용하는 것이다. 단순한 예로, 70%의 정확도를 가지는 모델이 5개 있다고 하자. 만약 이들이 서로 독립이라면, 이들의 결과로 다수결 투표를 진행했을 때의 정확도는 83.7% 에 달한다."]},{"cell_type":"markdown","metadata":{"id":"my_Uua7cPtUy","colab_type":"text"},"source":["이 때 중요한 것은 모델들이 서로 **독립**이어야 한다는 것이다. 독립이 아니라 똑같은 모델 5개이면 다수결을 해도 정확도는 70 %에서 변하지 않는다. 따라서 합의 기반 결합에서는 서로 독립인, 혹은 다양한 특징을 갖는 모델들을 생성해야 한다는 것이 매우 중요하다.  "]},{"cell_type":"markdown","metadata":{"id":"9MakQDcyNnJb","colab_type":"text"},"source":["### 합의 기반 결합 - Voting"]},{"cell_type":"markdown","metadata":{"id":"rHK_xnmWNpqu","colab_type":"text"},"source":["Voting 기법은 말 그대로 여러 개의 모델에게 정답이 무엇인지 투표시키는 방식을 말한다. 이 때 각 모델은 서로 다른 방법론을 통해 만들어진다. python의 scikit-learn 패키지의 [VotingClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html?highlight=votingclassifier#sklearn.ensemble.VotingClassifier) 를 이용해 기본적인 voting 방법론을 직접 실행해보자."]},{"cell_type":"markdown","metadata":{"id":"4twcgA9HJSpz","colab_type":"text"},"source":["[Covertype](https://archive.ics.uci.edu/ml/datasets/Covertype) 데이터셋을 사용해 보자. Scikit-learn의 [fetch_covtype](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_covtype.html#sklearn.datasets.fetch_covtype) 함수로 데이터를 받아올 수 있다."]},{"cell_type":"code","metadata":{"id":"GnRYGOS1SWVO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1595310079602,"user_tz":-540,"elapsed":79068,"user":{"displayName":"이예준","photoUrl":"","userId":"00427163814690958255"}},"outputId":"cba19a3f-4f9e-4001-d166-5df56b42c1ac"},"source":["from sklearn.datasets import fetch_covtype\n","x, y = fetch_covtype(return_X_y=True)\n","print(x.shape)\n","print(y.shape)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Downloading https://ndownloader.figshare.com/files/5976039\n"],"name":"stderr"},{"output_type":"stream","text":["(581012, 54)\n","(581012,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BS-GdghbSQzX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595310086259,"user_tz":-540,"elapsed":1308,"user":{"displayName":"이예준","photoUrl":"","userId":"00427163814690958255"}},"outputId":"05adc755-407d-41cc-acf1-43d9ea9395d6"},"source":["from sklearn.model_selection import train_test_split\n","\n","# 데이터 나누기\n","num_use_data = 2000\n","x = x[:num_use_data, :]\n","y = y[:num_use_data]\n","\n","x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)\n","\n","print(x_train.shape, x_test.shape)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["(1600, 54) (400, 54)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jdJeVc-DXcrq","colab_type":"text"},"source":["VotingClassifier를 학습하기 위해, 수업에서 배웠던 세 가지 분류기들을 이용해 보자. 먼저 필요한 모델들을 import 한 후 각각 생성하자."]},{"cell_type":"code","metadata":{"id":"isDZPeJ0JSaC","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595310117484,"user_tz":-540,"elapsed":1335,"user":{"displayName":"이예준","photoUrl":"","userId":"00427163814690958255"}}},"source":["from sklearn.ensemble import VotingClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import SVC\n","from sklearn.tree import DecisionTreeClassifier"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"tJCcrigoGOS8","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595310142578,"user_tz":-540,"elapsed":1499,"user":{"displayName":"이예준","photoUrl":"","userId":"00427163814690958255"}}},"source":["# 모델 객체 생성하기\n","log_clf = LogisticRegression()\n","dt_clf = DecisionTreeClassifier(random_state=1)\n","svm_clf = SVC()\n","\n","voting_clf = VotingClassifier(\n","    estimators=[('lr', log_clf), \n","                ('dt', dt_clf), \n","                ('svc', svm_clf)])"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1Cuo7quGTczW","colab_type":"text"},"source":["각 모델들을 학습시킨 후 정확도를 비교해 보자."]},{"cell_type":"code","metadata":{"id":"gQiW4df2FVkt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1595310153411,"user_tz":-540,"elapsed":1788,"user":{"displayName":"이예준","photoUrl":"","userId":"00427163814690958255"}},"outputId":"20422581-5819-42bf-e052-5c56c1e89a08"},"source":["# 각 모델 학습 및 정확도 확인하기\n","from sklearn.metrics import accuracy_score\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","voting_clf.fit(x_train, y_train)\n","pred_test = voting_clf.predict(x_test)\n","print(f'voting accuracy: {accuracy_score(y_test, pred_test)}')\n","\n","for name, estimator in voting_clf.named_estimators_.items():\n","  estimator.fit(x_train, y_train)\n","  pred_test_estim = estimator.predict(x_test)\n","  print(f'{name}: {accuracy_score(y_test, pred_test_estim)}')"],"execution_count":5,"outputs":[{"output_type":"stream","text":["voting accuracy: 0.69\n","lr: 0.615\n","dt: 0.7475\n","svc: 0.605\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sZpAkmT5WXEX","colab_type":"text"},"source":["VotingClassifier의 파라미터 중 하나인 voting은 다수결의 방식을 뜻한다. Default인 'hard'는 각 모델이 표를 하나씩 행사하는 방식이며, 'soft'는 각 모델의 분류 확률을 모두 더해 가장 높은 확률로 예측하는 방식이다. 일반적으로 soft voting 방식이 더 효과가 좋다고 알려져 있다. 이를 구현하고 위의 hard voting 방식과 비교해 보자."]},{"cell_type":"code","metadata":{"id":"Kh8eItRS65ah","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595310812278,"user_tz":-540,"elapsed":555,"user":{"displayName":"이예준","photoUrl":"","userId":"00427163814690958255"}}},"source":["# TODO: soft voting 방식으로 모델 생성하기\n","log_clf_soft = LogisticRegression()\n","dt_clf_soft = DecisionTreeClassifier(random_state=1)\n","svm_clf_soft = SVC(probability=True)\n","\n","voting_clf_soft = VotingClassifier(\n","    estimators=[('lr', log_clf_soft), \n","                ('dt', dt_clf_soft), \n","                ('svc', svm_clf_soft)],\n","    voting = 'soft'\n","    )"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"xb5fgQ1tSuwz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1595310822743,"user_tz":-540,"elapsed":4083,"user":{"displayName":"이예준","photoUrl":"","userId":"00427163814690958255"}},"outputId":"72e6e05c-7a85-4ffa-8ef1-dcd2e336d058"},"source":["# TODO: soft voting 방식으로 생성한 모델 학습하기\n","voting_clf_soft.fit(x_train, y_train)\n","pred_test = voting_clf_soft.predict(x_test)\n","print(f'voting accuracy: {accuracy_score(y_test, pred_test)}')\n","\n","for name, estimator in voting_clf_soft.named_estimators_.items():\n","  estimator.fit(x_train, y_train)\n","  pred_test_estim = estimator.predict(x_test)\n","  print(f'{name}: {accuracy_score(y_test, pred_test_estim)}')"],"execution_count":16,"outputs":[{"output_type":"stream","text":["voting accuracy: 0.765\n","lr: 0.615\n","dt: 0.7475\n","svc: 0.605\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yKnFe32_Zg33","colab_type":"text"},"source":["### 합의 기반 결합 - Bagging"]},{"cell_type":"markdown","metadata":{"id":"3wkJqsm6ZjQC","colab_type":"text"},"source":["Bagging 기법은 voting과 달리 하나의 머신 러닝 방법론을 사용하지만, 주어진 학습 데이터나 변수를 모두 사용하지 않고 임의로 추출하여 다양한 모델을 학습시킨 후 이들의 합의 기반 결합을 진행한다. "]},{"cell_type":"markdown","metadata":{"id":"z21Kfn7Qabxs","colab_type":"text"},"source":["![](https://upload.wikimedia.org/wikipedia/commons/thumb/c/c8/Ensemble_Bagging.svg/512px-Ensemble_Bagging.svg.png)"]},{"cell_type":"markdown","metadata":{"id":"pbbfOc2KaeJs","colab_type":"text"},"source":["Bagging의 종류는 각 모델의 학습용 데이터를 어떻게 구성하느냐에 따라 아래의 네 가지로 구분지을 수 있다.\n","\n","\n","* Pasting: 같은 데이터를 중복해서 추출하지 않음\n","* Bagging: 같은 데이터 샘플을 중복해서 추출\n","* Random Subspace: 데이터가 아니라 주어진 독립 변수 중 일부를 랜덤 추출\n","* Random Patches: 데이터와 독립 변수 모두 랜덤 추출해서 사용\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"GKwFpPJ40yda","colab_type":"text"},"source":["![alt text](https://datascienceschool.net/upfiles/677f18a151c64e5daa9c28f6cb564808.png)"]},{"cell_type":"markdown","metadata":{"id":"mQmzAMrofzLy","colab_type":"text"},"source":["먼저 일반적인 의사결정 나무 분류기를 학습한 후, [BaggingClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html?highlight=bagging#sklearn.ensemble.BaggingClassifier)를 이용해 bagging을 적용한 의사결정 나무 분류기를 학습해 보자."]},{"cell_type":"code","metadata":{"id":"dJrSZbGKc7ev","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595311443676,"user_tz":-540,"elapsed":1670,"user":{"displayName":"이예준","photoUrl":"","userId":"00427163814690958255"}},"outputId":"c289de0c-231b-4da0-9d4f-3c7fbff89881"},"source":["tree_clf = DecisionTreeClassifier(random_state=1)\n","tree_clf.fit(x_train, y_train)\n","pred_test = tree_clf.predict(x_test)\n","print(f'accuracy: {accuracy_score(y_test, pred_test)}')"],"execution_count":17,"outputs":[{"output_type":"stream","text":["accuracy: 0.7475\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QVkQn1PYdH8K","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595311450127,"user_tz":-540,"elapsed":1191,"user":{"displayName":"이예준","photoUrl":"","userId":"00427163814690958255"}}},"source":["from sklearn.ensemble import BaggingClassifier"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"HZEK3cNOVIt0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595311619009,"user_tz":-540,"elapsed":555,"user":{"displayName":"이예준","photoUrl":"","userId":"00427163814690958255"}},"outputId":"3ab2aa2b-13dc-4791-ca28-9e82c3beb33f"},"source":["# TODO: BaggingClassifier를 사용해 의사결정 나무 분류기 학습 및 정확도 계산하기\n","bagging_clf = BaggingClassifier(base_estimator=tree_clf,\n","                        n_estimators=10, random_state=0).fit(x_train, y_train)\n","\n","pred_test = bagging_clf.predict(x_test)\n","print(f'accuracy: {accuracy_score(y_test, pred_test)}')"],"execution_count":21,"outputs":[{"output_type":"stream","text":["accuracy: 0.865\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Zmdh8bfOh9ye","colab_type":"text"},"source":["의사결정 나무에서 배운 재귀적 분기에 대해 떠올려보자. 분기를 할 후보들을 각 독립 변수들로 정렬한 후에 최적의 분기점을 불순도 함수를 이용해 찾는다고 배웠다. 이 때, 모든 독립 변수를 사용하는 것이 아니라 **일부**만을 골라 분기 후보를 찾는다면, 더 빠른 계산이 가능하다. 이것이 바로 위에서 말한 random subspace 혹은 random patches의 개념을 적용한 것이다."]},{"cell_type":"markdown","metadata":{"id":"DVC7qophikYR","colab_type":"text"},"source":["즉, random patches를 의사결정 나무에 사용한 것이 바로 RandomForest 이다. Scikit-learn 에서는 [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html?highlight=randomforest#sklearn.ensemble.RandomForestClassifier)에서 이 모델을 제공하고 있으니, 이를 사용해서 분류해 보자."]},{"cell_type":"code","metadata":{"id":"Ch7yns17VK0Q","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595311628826,"user_tz":-540,"elapsed":581,"user":{"displayName":"이예준","photoUrl":"","userId":"00427163814690958255"}}},"source":["from sklearn.ensemble import RandomForestClassifier"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"_h6fwI5meq7s","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1595311742619,"user_tz":-540,"elapsed":29482,"user":{"displayName":"이예준","photoUrl":"","userId":"00427163814690958255"}},"outputId":"0f4beb7b-bcba-4318-8103-c85dbbbb56ef"},"source":["# TODO: RandomForestClassifier를 사용해 분류기 학습 및 정확도 계산하기\n","rf_clf = RandomForestClassifier(random_state=1)\n","rf_clf.fit(x_train, y_train)\n","pred_test = rf_clf.predict(x_test)\n","print(f'accuracy: {accuracy_score(y_test, pred_test)}')\n","\n","bagging_clf = BaggingClassifier(base_estimator=rf_clf,\n","                        n_estimators=100, random_state=0).fit(x_train, y_train)\n","\n","pred_test = bagging_clf.predict(x_test)\n","print(f'bagged accuracy: {accuracy_score(y_test, pred_test)}')"],"execution_count":24,"outputs":[{"output_type":"stream","text":["accuracy: 0.83\n","bagged accuracy: 0.8425\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"AtN3ccdf8A0e","colab_type":"text"},"source":["GridSearchCV를 이용해 최고의 파라미터 조합을 찾아보자."]},{"cell_type":"code","metadata":{"id":"WsJB50RMpQDz","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595312229134,"user_tz":-540,"elapsed":539,"user":{"displayName":"이예준","photoUrl":"","userId":"00427163814690958255"}}},"source":["from sklearn.model_selection import GridSearchCV"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"CnFaFPChpSQ-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":749},"executionInfo":{"status":"error","timestamp":1595312333457,"user_tz":-540,"elapsed":581,"user":{"displayName":"이예준","photoUrl":"","userId":"00427163814690958255"}},"outputId":"c1c73b96-f604-46ae-b695-1733df6ad01b"},"source":["# TODO: GridSearchCV를 이용해 최적의 조합을 찾고 그 때의 정확도 계산하기\n","param_grid2 = {'criterion': ['gini','entropy'], \n","              'max_depth': [50, 100, 300],\n","               'min_samples_splitint': [2,10,50]}\n","\n","bagging_clf_grid = GridSearchCV(estimator=bagging_clf, param_grid=param_grid2, cv=4, scoring='accuracy')\n","bagging_clf_grid.fit(x_train, y_train)\n","\n","print(bagging_clf_grid.best_params_)\n","print(bagging_clf_grid.best_score_)"],"execution_count":30,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-3d6d77d4a175>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mbagging_clf_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbagging_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mbagging_clf_grid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbagging_clf_grid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1027\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0mcloned_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mcloned_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mset_params\u001b[0;34m(self, **params)\u001b[0m\n\u001b[1;32m    234\u001b[0m                                  \u001b[0;34m'Check the list of available parameters '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m                                  \u001b[0;34m'with `estimator.get_params().keys()`.'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m                                  (key, self))\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdelim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Invalid parameter criterion for estimator BaggingClassifier(base_estimator=RandomForestClassifier(bootstrap=True,\n                                                        ccp_alpha=0.0,\n                                                        class_weight=None,\n                                                        criterion='gini',\n                                                        max_depth=None,\n                                                        max_features='auto',\n                                                        max_leaf_nodes=None,\n                                                        max_samples=None,\n                                                        min_impurity_decrease=0.0,\n                                                        min_impurity_split=None,\n                                                        min_samples_leaf=1,\n                                                        min_samples_split=2,\n                                                        min_weight_fraction_leaf=0.0,\n                                                        n_estimators=100,\n                                                        n_jobs=None,\n                                                        oob_score=False,\n                                                        random_state=1,\n                                                        verbose=0,\n                                                        warm_start=False),\n                  bootstrap=True, bootstrap_features=False, max_features=1.0,\n                  max_samples=1.0, n_estimators=100, n_jobs=None,\n                  oob_score=False, random_state=0, verbose=0, warm_start=False). Check the list of available parameters with `estimator.get_params().keys()`."]}]},{"cell_type":"code","metadata":{"id":"zOcLcJ2LBKiV","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}